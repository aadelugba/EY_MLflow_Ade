{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from hyperopt import tpe, hp, fmin, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "mlflow.set_experiment(\"boston prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Search Space\n",
    "space = { \n",
    "    'boosting_type': hp.choice('boosting_type', ['gbdt','goss']),\n",
    "    'metric': hp.choice('metric',['rmse']),\n",
    "    'max_depth':scope.int(hp.quniform('max_depth', 2, 16, 1)),\n",
    "    'min_data_in_leaf': scope.int(hp.quniform('min_data_in_leaf', 30, 150, 1)),\n",
    "    'num_leaves': scope.int(hp.quniform('num_leaves', 30, 150, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 10),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 10),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n",
    "    \"feature_pre_filter\": hp.choice(\"feature_pre_filter\",[False])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "def objective(params, n_folds = N_FOLDS):\n",
    "    \"\"\"Objective function for Light Gradient Boosting Machine Hyperparameter Tuning\"\"\"\n",
    "    \n",
    "    # Perform n_fold cross validation with hyperparameters\n",
    "    cv_results = lgb.cv(params, train_set, nfold = n_folds,num_boost_round=400,stratified=False, \n",
    "                        early_stopping_rounds = 30, seed = 50)\n",
    "    print(params)\n",
    "    print(cv_results)\n",
    "    # Extract the best score\n",
    "    best_score = min(cv_results['rmse-mean'])\n",
    "# Dictionary with information for evaluation\n",
    "    return {'loss': best_score, 'params': params, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EVALS = 10\n",
    "bayes_trials = Trials()\n",
    "print('optimization starting')\n",
    "# Optimize\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "                max_evals = MAX_EVALS, trials = bayes_trials)\n",
    "print('optimization complete')\n",
    "best_model = bayes_trials.results[np.argmin([r['loss'] for r in \n",
    "        bayes_trials.results])]\n",
    "params=best_model['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run: \n",
    "        # Training LightGBM model\n",
    "         gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=500,\n",
    "                        valid_sets=lgb_eval,\n",
    "                        early_stopping_rounds=30)\n",
    "\n",
    "        y_test['pred'] = gbm.predict(x_test, num_iteration=gbm.best_iteration)\n",
    "\n",
    "        (rmse, mae, r2) = eval_metrics(y_test.iloc[:,3], y_test['pred'])\n",
    "\n",
    "        y_test['mae']=abs(y_test['target']-y_test['pred'])\n",
    "        # tracking run parameters\n",
    "        mlflow.log_param(\"hyper-parameters\", params)\n",
    "        mlflow.log_param(\"features\", x_train.columns)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.sklearn.log_model(gbm, \"model\")\n",
    "        modelpath = \"micro_{}_{}\".format(mod,valdate)\n",
    "        mlflow.lightgbm.save_model(gbm, modelpath)\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1a2a7e0bb8c2eb4bb83d0db03e33cfe6c525724c28ef03edefe88bb35831af0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
