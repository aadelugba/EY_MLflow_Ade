{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and libraries needed\n",
    "import mlflow\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "from mlflow.tracking import MlflowClient as mf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from hyperopt import tpe, hp, fmin, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "\n",
    "# Set Ml Flow experiment for tracking\n",
    "mlflow.set_experiment(\"Classification Model\")\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:20<00:00, 10.08s/trial, best loss: -0.9336666666666666]\n",
      "a62c477c99234057aab1438b01ca60ca\n"
     ]
    }
   ],
   "source": [
    "from functions.train_model import train_model, get_run_id\n",
    "print(get_run_id(train_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the following using Rapids functions cudf, and cuml --> it enables us run on GPUs which is far faster\n",
    "df = pd.read_csv(\"data/diabetes.csv\").drop('PatientID', axis=1)\n",
    "\n",
    "def train_model(params, test_size = 0.3, registered_model_name= None):\n",
    "    #max_depth, max_features, n_estimators = params\n",
    "    \n",
    "    # Split between features and label\n",
    "    X = df.drop([\"Diabetic\"], axis = 1)\n",
    "    y = df[\"Diabetic\"]\n",
    "    \n",
    "    # define training and test set based on split in function\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = 123)\n",
    "    \n",
    "    # model and fit\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # log model, params and artifact(s)\n",
    "    mlflow.sklearn.log_model(model, artifact_path=\"Model_Artifacts\", registered_model_name=registered_model_name)\n",
    "    #mlflow.log_params(params)\n",
    "    \n",
    "    # Log pickled file --- remove following since mlflow already pickles and logs\n",
    "    # output_path = \"output\"\n",
    "    # dump(model, output_path)\n",
    "    # mlflow.log_artifact(output_path)\n",
    "\n",
    "    # mlflow.sklearn.save_model(model, output_path)\n",
    "\n",
    " \n",
    "    # log tags, and metrics\n",
    "    if test_size > 0.0:\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        \n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"precision\", prec)\n",
    "        mlflow.log_metric(\"recall\", rec)\n",
    "        \n",
    "    else:\n",
    "        acc = np.nan\n",
    "        prec = np.nan\n",
    "        rec = np.nan\n",
    "    \n",
    "    # Since fmin (hyperopt) minimizes loss, we want to maximise acc -- which is the reverse --> return this loss function\n",
    "    return {'loss': -acc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this in cmd before running th code beneath it\n",
    "# mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts --host 0.0.0.0\n",
    "\n",
    "params = {\"max_features\": 0.7, \"n_estimators\": 100, \"max_depth\" : 10}\n",
    "train_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperOpt\n",
    "# Configure search space\n",
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
    "   # 'max_features': hp.choice(\"max_features\", [\"auto\", \"sqrt\"]),\n",
    "    'max_features': hp.uniform(\"max_features\", 0.0, 1.0),\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 200, 50))\n",
    "}\n",
    "\n",
    "algo = tpe.suggest\n",
    "\n",
    "# Define spark trials object - for Databricks, this keeps track of all your trials and integrates with databricks UI\n",
    "trials = Trials()\n",
    "\n",
    "mlflow.end_run() # close out any run in progress\n",
    "\n",
    "# Run mlflow with the hyper parameter tuning job\n",
    "# fmin returns best parameters \n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.set_tags({\"model_type\": \"Classification Model\", \"resource_type\": \"POC Work\"})\n",
    "    best = fmin(\n",
    "                fn = train_model,\n",
    "                space = search_space,\n",
    "                algo = algo,\n",
    "                trials = trials,\n",
    "                max_evals = 2,\n",
    "            )\n",
    "    \n",
    "    #output_path = \"output\"\n",
    "\n",
    "    mlflow.set_tag(\"best_params\", str(best))\n",
    "\n",
    "    # mlflow.sklearn.save_model(best, output_path) # gives an error if path already exists\n",
    "\n",
    "    best_params = {\"max_features\": best[\"max_features\"], \"n_estimators\": int(best[\"n_estimators\"]), \"max_depth\" : int(best[\"max_depth\"])}\n",
    "    # train_model(best_params, test_size = 0.0001, registered_model_name=\"Diabetes_Prediction\") # registered_model_name kept giving an error --> investigate\n",
    "    # RestException: INVALID_PARAMETER_VALUE:  Model registry functionality is unavailable; got unsupported URI './mlruns' for model registry data storage. Supported URI schemes are: ['postgresql', 'mysql', 'sqlite', 'mssql']. See https://www.mlflow.org/docs/latest/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations.\n",
    "    \n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # fit the model without a test set --> with the whole data since w enow have best params\n",
    "    train_model(best_params)\n",
    "\n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ID and Artifact Path\n",
    "print(run_id)\n",
    "artifact_path = \"Model_Artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tried:\n",
    "# # mlflow models serve -m runs:/bce20ce3cc5f409e9de0c9bb4b13d415/model --port 1234\n",
    "# mlflow models serve --model-uri runs:/bce20ce3cc5f409e9de0c9bb4b13d415/model --no-conda\n",
    "# Error:\n",
    "# MlflowException: Run 'bce20ce3cc5f409e9de0c9bb4b13d415' not found\n",
    "\n",
    "# Tried:\n",
    "# mlflow models serve -m \"models:/Diabetes Prediction Model/Staging\" --port 1234\n",
    "# Error:\n",
    "# MlflowException: Model Registry features are not supported by the store with URI: 'file:///C:/Users/lugba/OneDrive/Desktop/InfoSys/EY_POC/Models/test_ml_flow/mlruns'. Stores with the following URI schemes are supported: ['databricks', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Model with Artifact Paths used in function, plus run Id and Model Name you want\n",
    "result = mlflow.register_model(\n",
    "    \"runs:/\" + run_id + \"/\" + artifact_path,\n",
    "    \"Diabetes Prediction Model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mf() # alias for MlflowClient \n",
    "\n",
    "model_name = \"Diabetes Prediction Model\"\n",
    "filter_string = \"name='{}'\".format(model_name)\n",
    "results = client.search_registered_models(filter_string=filter_string)\n",
    "for res in results:\n",
    "    for mv in res.latest_versions:\n",
    "        # print(\"name={}; run_id={}; version={}\".format(mv.name, mv.run_id, mv.version))\n",
    "        model_version = mv.version\n",
    "    print(model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition to Staging\n",
    "client.transition_model_version_stage(\n",
    "    name = model_name,\n",
    "    version= model_version,\n",
    "    stage = 'staging',\n",
    ")\n",
    "\n",
    "# # Transition model version and retrieve details using API\n",
    "# # https://docs.databricks.com/applications/mlflow/model-registry-example.html#:~:text=%20MLflow%20Model%20Registry%20example%20%201%20Load,component%20defines%20functions%20for%20loading%20models...%20More%20?msclkid=79201fa1b94311eca1609084b53d7e5c\n",
    "# client.transition_model_version_stage(\n",
    "#   name=model_details.name,\n",
    "#   version=model_details.version,\n",
    "#   stage='Production',\n",
    "# )\n",
    "# model_version_details = client.get_model_version(\n",
    "#   name=model_details.name,\n",
    "#   version=model_details.version,\n",
    "# )\n",
    "# print(\"The current model stage is: '{stage}'\".format(stage=model_version_details.current_stage))\n",
    "\n",
    "# latest_version_info = client.get_latest_versions(model_name, stages=[\"Production\"])\n",
    "# latest_production_version = latest_version_info[0].version\n",
    "# print(\"The latest production version of the model '%s' is '%s'.\" % (model_name, latest_production_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_recent_run = mlflow.sklearn.load_model(\"runs:/\" + run_id + \"/\" + artifact_path)\n",
    "type(model_recent_run)\n",
    "\n",
    "test_data_no_ID = [0, 171, 80, 34, 23, 43.509726, 1.213191, 21]\n",
    "test_data_reshaped_noID = np.array(test_data_no_ID).reshape(1,-1)\n",
    "prediction = model_recent_run.predict(test_data_reshaped_noID)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "# Load recent model\n",
    "model_version_uri = \"models:/{model_name}/{model_version}\".format(model_name=model_name, model_version=model_version)\n",
    "\n",
    "print(\"Loading registered model version from URI: '{model_uri}'\".format(model_uri=model_version_uri))\n",
    "model_version_latest = mlflow.pyfunc.load_model(model_version_uri)\n",
    "\n",
    "# load model in staging\n",
    "model_staging_uri = \"models:/{model_name}/staging\".format(model_name=model_name)\n",
    "\n",
    "print(\"Loading registered model version from URI: '{model_uri}'\".format(model_uri=model_staging_uri))\n",
    "model_staging = mlflow.pyfunc.load_model(model_staging_uri)\n",
    "\n",
    "# # load model in production\n",
    "# model_production_uri = \"models:/{model_name}/production\".format(model_name=model_name)\n",
    "\n",
    "# print(\"Loading registered model version from URI: '{model_uri}'\".format(model_uri=model_production_uri))\n",
    "# model_production = mlflow.pyfunc.load_model(model_production_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_no_ID = [0, 171, 80, 34, 23, 43.509726, 1.213191, 21]\n",
    "test_data_reshaped_noID = np.array(test_data_no_ID).reshape(1,-1)\n",
    "prediction_latest = model_version_latest.predict(test_data_reshaped_noID)\n",
    "print(prediction_latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying out this function for flask --- don't know why it is not working within flask\n",
    "def mlflow_model_version():\n",
    "    client = MlflowClient() # alias for MlflowClient \n",
    "    model_name = \"Diabetes Prediction Model\"\n",
    "    filter_string = \"name='{}'\".format(model_name)\n",
    "    results = client.search_registered_models(filter_string=filter_string)\n",
    "    for res in results:\n",
    "        for mv in res.latest_versions:\n",
    "        # print(\"name={}; run_id={}; version={}\".format(mv.name, mv.run_id, mv.version))\n",
    "            model_version = mv.version\n",
    "\n",
    "    return model_name, model_version\n",
    "\n",
    "def preprocessDataAndPredict(Pregnancies, PlasmaGlucose, DiastolicBloodPressure, TricepsThickness, SerumInsulin, BMI, DiabetesPedigree, Age):\n",
    "    test_data = [Pregnancies, PlasmaGlucose, DiastolicBloodPressure, TricepsThickness, SerumInsulin, BMI, DiabetesPedigree, Age]\n",
    "    test_data = np.array(test_data)\n",
    "    test_data = test_data.reshape(1,-1)\n",
    "    model_name, model_version = mlflow_model_version()\n",
    "    model_version_uri = \"models:/{model_name}/{model_version}\".format(model_name=model_name, model_version=model_version)\n",
    "    trained_model = mlflow.pyfunc.load_model(model_version_uri)    # trained_model = joblib.load(\"output/model.pkl\")\n",
    "    prediction = trained_model.predict(test_data)\n",
    "    return prediction\n",
    "\n",
    "model_name, model_version = mlflow_model_version()\n",
    "print(\"Model Name: {}\\n Model Version: {}\".format(model_name, model_version))\n",
    "model_version_uri = \"models:/{model_name}/{model_version}\".format(model_name=model_name, model_version=model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model from latest registered version\n",
    "test_model = mlflow.pyfunc.load_model(model_version_uri)\n",
    "test_pred = test_model.predict(test_data_reshaped_noID)\n",
    "print(\"Printing Test Prediction Results\")\n",
    "print(test_pred)\n",
    "\n",
    "print(\"Printing Function Prediction Results\")\n",
    "func_pred = preprocessDataAndPredict(0, 171, 80, 34, 23, 43.509726, 1.213191, 21)\n",
    "(func_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.active_run().info.run_id"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1a2a7e0bb8c2eb4bb83d0db03e33cfe6c525724c28ef03edefe88bb35831af0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
